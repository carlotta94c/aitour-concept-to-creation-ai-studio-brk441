{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating generation quality performance metrics of the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring Azure OpenAI service connection\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from promptflow.core import AzureOpenAIModelConfiguration\n",
    "\n",
    "# Initialize Azure OpenAI Connection\n",
    "model_config = AzureOpenAIModelConfiguration(\n",
    "        azure_deployment=\"gpt-4\",\n",
    "        api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "        azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "        api_key=os.environ[\"AZURE_OPENAI_KEY\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Create the website copy for the tents catalog ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Create the textual assets for the sleeping bag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Draft the website copy for the hiking shoes we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question\n",
       "0  Create the website copy for the tents catalog ...\n",
       "1  Create the textual assets for the sleeping bag...\n",
       "2  Draft the website copy for the hiking shoes we..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uploading test dataset\n",
    "import pandas as pd\n",
    "\n",
    "data_path = \"../data/test_dataset.jsonl\"\n",
    "\n",
    "df = pd.read_json(data_path, lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing class evaluators \n",
    "\n",
    "from create_website_copy_request import get_response\n",
    "from promptflow.evals.evaluators import RelevanceEvaluator, GroundednessEvaluator, FluencyEvaluator, CoherenceEvaluator\n",
    "\n",
    "relevance_evaluator = RelevanceEvaluator(model_config)\n",
    "groundedness_evaluator = GroundednessEvaluator(model_config)\n",
    "fluency_evaluator = FluencyEvaluator(model_config)\n",
    "coherence_evaluator = CoherenceEvaluator(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240905133415_chat_evaluation_sdk\n"
     ]
    }
   ],
   "source": [
    "# Create unique id for each run with date and time\n",
    "from datetime import datetime\n",
    "run_id = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "run_id = f\"{run_id}_chat_evaluation_sdk\"    \n",
    "print(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = os.environ[\"AZURE_SUBSCRIPTION_ID\"]\n",
    "resource_group_name= os.environ[\"AZURE_RESOURCE_GROUP\"]\n",
    "project_name = os.environ[\"AZURE_AI_PROJECT_NAME\"]\n",
    "\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": subscription_id,\n",
    "    \"resource_group_name\": resource_group_name,\n",
    "    \"project_name\": project_name\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Run web_designer_app against test dataset\n",
    "# Step 2: Evaluate prompt flow outputs (answer and context) against generation quality metrics\n",
    "from promptflow.evals.evaluate import evaluate\n",
    "\n",
    "result_eval = evaluate(\n",
    "    evaluation_name=run_id,\n",
    "    data=data_path,\n",
    "    target=get_response,\n",
    "    evaluators={\n",
    "        \"relevance\": relevance_evaluator,\n",
    "        \"fluency\": fluency_evaluator,\n",
    "        \"coherence\": coherence_evaluator,\n",
    "        \"groundedness\": groundedness_evaluator,\n",
    "    },\n",
    "    # column mapping    return {\"question\": question, \"answer\": result, \"context\": context}\n",
    "    evaluator_config={\n",
    "        \"defaultS\": {\n",
    "            \"question\": \"${data.question}\",\n",
    "            \"answer\": \"${target.answer}\",\n",
    "            \"context\": \"${target.context}\",\n",
    "        },\n",
    "    },\n",
    "    azure_ai_project = azure_ai_project, # comment this line if you don't want to push results to your Azure AI Project\n",
    "    output_path=\"./eval_results.jsonl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Summarized Metrics-----\n",
      "{'relevance.gpt_relevance': 5.0, 'fluency.gpt_fluency': 5.0, 'coherence.gpt_coherence': 5.0, 'groundedness.gpt_groundedness': 5.0}\n",
      "-----Tabular Result-----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outputs.answer</th>\n",
       "      <th>outputs.context</th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.relevance.gpt_relevance</th>\n",
       "      <th>outputs.fluency.gpt_fluency</th>\n",
       "      <th>outputs.coherence.gpt_coherence</th>\n",
       "      <th>outputs.groundedness.gpt_groundedness</th>\n",
       "      <th>line_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>## Tents Catalog\\n\\n### TrailMaster X4 Tent\\n*...</td>\n",
       "      <td>## Task\\nYou serve as a web copywriter for the...</td>\n",
       "      <td>Create the website copy for the tents catalog ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>### CozyNights Sleeping Bag\\n\\n**Embrace the G...</td>\n",
       "      <td>## Task\\nYou serve as a web copywriter for the...</td>\n",
       "      <td>Create the textual assets for the sleeping bag...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>### TrekReady TrailWalker Hiking Shoes\\n\\n**Ad...</td>\n",
       "      <td>## Task\\nYou serve as a web copywriter for the...</td>\n",
       "      <td>Draft the website copy for the hiking shoes we...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      outputs.answer  \\\n",
       "0  ## Tents Catalog\\n\\n### TrailMaster X4 Tent\\n*...   \n",
       "1  ### CozyNights Sleeping Bag\\n\\n**Embrace the G...   \n",
       "2  ### TrekReady TrailWalker Hiking Shoes\\n\\n**Ad...   \n",
       "\n",
       "                                     outputs.context  \\\n",
       "0  ## Task\\nYou serve as a web copywriter for the...   \n",
       "1  ## Task\\nYou serve as a web copywriter for the...   \n",
       "2  ## Task\\nYou serve as a web copywriter for the...   \n",
       "\n",
       "                                     inputs.question  \\\n",
       "0  Create the website copy for the tents catalog ...   \n",
       "1  Create the textual assets for the sleeping bag...   \n",
       "2  Draft the website copy for the hiking shoes we...   \n",
       "\n",
       "   outputs.relevance.gpt_relevance  outputs.fluency.gpt_fluency  \\\n",
       "0                              5.0                          5.0   \n",
       "1                              5.0                          5.0   \n",
       "2                              5.0                          5.0   \n",
       "\n",
       "   outputs.coherence.gpt_coherence  outputs.groundedness.gpt_groundedness  \\\n",
       "0                              5.0                                    5.0   \n",
       "1                              5.0                                    5.0   \n",
       "2                              5.0                                    5.0   \n",
       "\n",
       "   line_number  \n",
       "0            0  \n",
       "1            1  \n",
       "2            2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result = pd.DataFrame(result_eval[\"rows\"])\n",
    "print(\"-----Summarized Metrics-----\")\n",
    "print(result_eval[\"metrics\"])\n",
    "print(\"-----Tabular Result-----\")\n",
    "eval_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://ai.azure.com/build/evaluation/web_designer_app_20240905_133422_646778?wsid=/subscriptions/7566e977-87fc-4b9b-929f-f094d9e33427/resourceGroups/BRK441-2820_RG/providers/Microsoft.MachineLearningServices/workspaces/BRK441-2820-project'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the link to visualize eval results to Azure AI Studio\n",
    "result_eval[\"studio_url\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
